{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EAzHL9kVf69G"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5AsfyCDJgmR0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spam = pd.read_csv(\"vectorized.csv\")\n",
    "spam.drop([\"Unnamed: 0\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1TGJTcshOyi",
    "outputId": "ea542c3a-e407-4ce0-a3cd-a69ea8c05ede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'call': 342, 'free': 180, '2': 169, 'ur': 144, 'txt': 136}\n"
     ]
    }
   ],
   "source": [
    "# Get a list of stop words from https://gist.github.com/sebleier/554280\n",
    "with open('stopwords.txt') as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "\n",
    "def getTopSpam(df, commonWords, num):\n",
    "  '''\n",
    "  Returns the most common 'num' words in the spam messages.\n",
    "  '''\n",
    "  spam = {}\n",
    "  ham = []\n",
    "\n",
    "  # Gets count of all words in spam that are not in the list of common words\n",
    "  for idx in range(len(df.index)):\n",
    "    message = df.iat[idx, 1]\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "      if word not in commonWords and df.iat[idx, 0] == \"spam\":\n",
    "        if word not in spam:\n",
    "          spam[word] = 1\n",
    "        elif word in spam:\n",
    "          spam[word] = spam[word] + 1\n",
    "   \n",
    "  spam = sorted(spam.items(), key=lambda x:x[1], reverse=True)\n",
    "  return dict(spam[:num])\n",
    "\n",
    "result = getTopSpam(spam, lines, 5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zIlKBOC7lfl_"
   },
   "outputs": [],
   "source": [
    "def testTrainSplit(df):\n",
    "  length = len(spam.index)\n",
    "  split_limit = int(length * 0.7)\n",
    "  train = spam[0:split_limit]\n",
    "  test = spam[split_limit:length]\n",
    "  return train, test\n",
    "\n",
    "train, test = testTrainSplit(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "28wdz9zEgwQ4",
    "outputId": "16d8bd64-80f5-47c4-c75a-4b6fe48f8bc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call</th>\n",
       "      <th>free</th>\n",
       "      <th>2</th>\n",
       "      <th>ur</th>\n",
       "      <th>txt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   call  free  2  ur  txt label\n",
       "0     0     0  0   1    0   ham\n",
       "1     0     0  0   0    0   ham\n",
       "2     0     1  1   0    1  spam\n",
       "3     0     0  0   0    0   ham\n",
       "4     0     0  0   0    0   ham"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def makeVectorTable(df):\n",
    "  '''\n",
    "  This function displays the message vectors like the stolen car data table seen\n",
    "  in our first lecture on Naive Bayes.\n",
    "  '''\n",
    "  feature_records = []\n",
    "  for idx in range(len(df)):\n",
    "    feature_vector = []\n",
    "    msg = df.iat[idx, 1]\n",
    "    label = df.iat[idx, 0]\n",
    "    for word in result.keys():\n",
    "      feature_vector.append(1 if word in msg else 0)\n",
    "    feature_vector.append(label)\n",
    "    feature_records.append(feature_vector)\n",
    "  feature_df = pd.DataFrame(feature_records)\n",
    "  columns = list(result.keys())\n",
    "  columns.append('label')\n",
    "  feature_df.columns = columns\n",
    "  return feature_df\n",
    "  \n",
    "feature_df = makeVectorTable(train)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0Si4l8Pinbb",
    "outputId": "309bd615-cb18-4eae-ea5f-a6a62d3ec7c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13307692307692306 0.8669230769230769\n"
     ]
    }
   ],
   "source": [
    "def getProbHamSpam(df, feature_df):\n",
    "  '''\n",
    "  Gets the overall probability of ham and spam labels in dataframe\n",
    "  '''\n",
    "  p_spam = feature_df[feature_df.label == 'spam'].label.count() / feature_df.shape[0]\n",
    "  p_ham = feature_df[feature_df.label == 'ham'].label.count() / feature_df.shape[0]\n",
    "  return (p_spam, p_ham)\n",
    "\n",
    "pSpam, pHam = getProbHamSpam(spam, feature_df)\n",
    "print(pSpam, pHam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dtoiE24ojPeI",
    "outputId": "3c294bc7-ffab-4158-bae6-ae1fcbb99687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'call': 0.44315992292870904,\n",
       " 'free': 0.2678227360308285,\n",
       " '2': 0.7398843930635838,\n",
       " 'ur': 0.5953757225433526,\n",
       " 'txt': 0.26396917148362237}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getSpamWordProbs(feature_df):\n",
    "  ''' \n",
    "  Returns a dictionary of probabilities of 'top' words in messages labeled as spam.\n",
    "  '''\n",
    "  spam_df = feature_df[feature_df.label == 'spam']\n",
    "  spam_word_counts = spam_df[result.keys()].sum(axis=0)\n",
    "  spam_probs = spam_word_counts / spam_df.shape[0]\n",
    "  spam_probs = spam_probs.to_dict()\n",
    "  return spam_probs\n",
    "\n",
    "getSpamWordProbs(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76O8SRd1jnt8",
    "outputId": "63e621d2-7772-42a3-d317-fe4e5bf2b778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'call': 0.06033717834960071,\n",
       " 'free': 0.013309671694764862,\n",
       " '2': 0.06595681750961255,\n",
       " 'ur': 0.21177166518781426,\n",
       " 'txt': 0.0026619343389529724}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getHamWordProbs(feature_df):\n",
    "  ''' \n",
    "  Returns a dictionary of probabilities of 'top' words in messages labeled as spam.\n",
    "  '''\n",
    "  spam_df = feature_df[feature_df.label == 'ham']\n",
    "  spam_word_counts = spam_df[result.keys()].sum(axis=0)\n",
    "  spam_probs = spam_word_counts / spam_df.shape[0]\n",
    "  spam_probs = spam_probs.to_dict()\n",
    "  return spam_probs\n",
    "\n",
    "getHamWordProbs(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2360852682.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\achen12\\AppData\\Local\\Temp\\ipykernel_14208\\2360852682.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def naiveBabes:\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def naiveBabes:\n",
    "    for i in range(0, len(test.index)):\n",
    "        vector = <std::out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sykitlearn():\n",
    "    clf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainxvectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14208\\3516352642.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrainImpacted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainxvectors\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrainunpacked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainxvectors' is not defined"
     ]
    }
   ],
   "source": [
    "trainImpacted = [ ]\n",
    "for row in trainxvectors :\n",
    "    trainunpacked.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Ham\" , \"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
